%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                   %
%                      JAMI - LaTeX format                          %
%                                                                   %
%     E-mail address  : ryoocs@hnu.kr                               %
%                                                                   %
%                                                                   %
%                                                                   %
%   We are accepting manuscripts with AMSTeX or LaTeX versions      %
%   through E-mail.                                                 %
%                                                                   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[10pt,twoside,reqno]{amsart} %For LaTeX2e users

%\documentstyle[10pt,twoside]{amsart} %For old version of Latex users

\allowdisplaybreaks
\usepackage{amsmath,amstext,amssymb,braket}
\usepackage{graphicx}

\textwidth 12.2 cm
\textheight 19.3 cm
\oddsidemargin 1.2cm
\evensidemargin 1.2cm
\calclayout

\setcounter{page}{1}
%
\makeatletter
\renewcommand{\@seccntformat}[1]{\bf\csname the#1\endcsname. }
\renewcommand{\section}{\@startsection{section}{1}
   \z@{.7\linespacing\@plus\linespacing}{.5\linespacing}
   {\normalfont\upshape\bfseries\centering}}
%\@addtoreset{thm}{section} \@addtoreset{rem}{section}
\renewcommand{\@biblabel}[1]{\@ifnotempty{#1}{#1.}}
\makeatother
%
\renewcommand{\refname}{\sc References}
%
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{pro}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{exa}[thm]{Example}
\newtheorem{defn}[thm]{Definition}
\newtheorem{rem}{Remark}[section]

\def\pn{\par\noindent}


\begin{document}

\leftline{\scriptsize \it  J. Appl. Math. {$\&$}
Informatics Vol. {\bf 4x}(2023), No. x, pp. xx - xx   }
\vspace{-0.15cm}
%\leftline{\footnotesize Website: http://www.jami.or.kr}
\leftline{\footnotesize https://doi.org/10.14317/jami.201x.xxx}



\vspace{1.3cm}

\title
{ %Full title of the paper
Constructions of Block-encloding and their effects on Quantum Speedups$^\dagger$  
}

\author
{ %Firstname Lastname, Firstname Lastname
  Hyeonmin Roh$^*$, Taewon Kim$^{**}$ 
}

\thanks{ {\scriptsize  Received     ,     .  Revised ,   .    Accepted     ,   . \enskip $^*$Corresponding author.}\\
\indent{\scriptsize $^\dagger$%funding-------------------------------------------------------------------
{Please add: ``This research received no external funding'' or ``This research was funded by NAME OF FUNDER grant number XXX.'' and  and ``The APC was funded by XXX''. Check carefully that the details given are accurate and use the standard spelling of funding agency names, any errors may affect your future funding.}
Example:This work was supported by the research grant of the University}\\
\indent{\scriptsize $\copyright$ 2023 KSCAM}}


\maketitle


\begin{abstract}
Abstract is here, not exceeding {\it 160} words. It must contain {\it Main Facts}.

\vskip 0.4 true cm


\noindent
 AMS Mathematics Subject Classification : 65H05, 65F10.

\noindent 
{\it Key words and phrases } : %keyword 1, keyword 2, keyword 3.
Nonlinear equation, three-step iterative method, multi-step iterative method.

\end{abstract}


\pagestyle{myheadings}
\markboth{\centerline {\scriptsize  the names of the authors  }}
         {\centerline {\scriptsize  title of paper  }}


\bigskip
\section{Introcution}
On claimed exponential speedups of quantum machine learning algorithms
subsequent to HHL algorithm for solving linear system of equations,
Tang presented classical counterparts for fair amount of QML algorithms
by exploiting basic linear algebraic properties underlying data structures 
used during accessing matrices in a quantum-advantable way, and corresponding
them to classical randomied numerical linear algebra methods. Such process is
termed `dequantization'. 

All known linear algebraic QML techinques are captured by Quantum singluar 
vlaue transformation (QSVT), a unifying framework of quantum algorithms.
QSVT can be classified by their input model assumptions, whether if
inputs for QML are sparse or low-rank. Since sparse-access input models
are known to give expnential speedup, dequantization attacks low-rank
input models, where classical data without strong restrictions are appliable.

For classical data, QML algorithms must efficiently prepair them as qunatum
states. So we assume the existence of quantum random access memory (QRAM), 
a qunatum device corresponding to classical RAM. QRAM stores $n$ bits of data
and query those data in superposition by a $\textrm{polylog}(n)$ time. 
Dequantization is essentially the process of providing psuedo-QRAM to classical
computers, by assumming a input model of sampeling and query access to a vector,
which would lead to a fair comparison between quantum and classical machine
learning.

Results of dequantization draw a border line for our understanding of QML
algorithms and their limitations. Hence, one of the open problems of
QML is whether there exist other ways to construct data structures that
prevent dequantizaition. We focus on this matter by its basic unit, termed
`Block-encoding'. Our goal is to formally define two alternative data structure
implicitly stated by Kerenidis and Prakash, and CHakraborty, Gily\'en, and
Jeffery, generelizing sparse-input model to QRAM-input model.

\section{Nomenclature}

\section{Block-encoding}
What lets an algorithm to be dequantized? Below is a QRAM data structure used
for the recommendation algorithm, which is the first algorithm to be dequantized.
\begin{thm}[Kerenidis 2017, Theorem 15]
  Let $A\in\mathbb{R}^{m\times n}$ be a matrix with $A_{ij}\in\mathbb{R}$ being
  the entry of the $i$-th row and the $j$-th column. If $w$ is the number of
  entries that have already arrived in the system, given the entries $(i,j,A_{ij}$
  in an arbitrary order, there exists a data structure to store the matrix
  $A$ with the following properties:
  \begin{enumerate}
    \item The size of the data structure is $\mathcal{O}(w\log^2(mn))$.
    \item Given the entries $(i,j,A_{ij})$ in an arbitrary order, the time
      to store them is $\mathcal{O}(\log^2(mn))$.
    \item There exists a quantum algorithm that can perform the following maps
      in $\textrm{\normalfont polylog}(mn)$ time for $i\in[m]$ and $j\in[n]$:
      \begin{align*}
        \widetilde{U}&: \ket{i}\ket0\mapsto\ket{i}\ket{A_i},\\
        \widetilde{V}&: \ket0\ket{j}\mapsto\ket{\widetilde{A}}\ket{j},
      \end{align*}
      where $\widetilde{A}\in\mathbb{R}^m$ has entries $\widetilde{A_i}=\|A_i\|$.
  \end{enumerate}
\end{thm}
\begin{proof}
  The data structure consists of an array of $m$ binary trees $B_i,i\in[m]$.
  When a new entry $(i,j,A_{ij}$ arrives the leaf node $j$, in tree $B_i$ is
  created if not present and updated otherwise. The depth of each tree $B_i$
  is at most $\lceil\log n\rceil$. An internal node $v$ of $B_i$ stores the sum
  of the values of all leaves in the subtree rooted at $v$, i.e. the sum of
  the square amplitudes of the entries of $A_i$ in the subtree. Hence, the value
  stored at the root is $\|A_i\|^2$. 
  \begin{enumerate}
    \item The memory required for the data structure is $\mathcal{O}(w\log^2 mn)$
      as for each entry $(i,j,A_{ij}$ at most $\lceil\log n\rceil$ new nodes are
      added, each node requiring $\mathcal{O}(\log mn)$ bits.
    \item The time required to store entry $(i,j,A_{ij})$ is $\mathcal{O}(\log^2
      mn)$ as the insertion algorithm makes at most $\lceil \log n\rceil$ updates
      to the data structure and each update requires time $\mathcal{O}(\log mn)$
      to retrieve the address of the updated node.
    \item The amplitudes stored in the internal nodes of $B_i$ are used to
      apply a sequence of conditional rotations to the initial state
      $\ket0^{\lceil\log n\rceil}$ to obtain $\ket{A_i}$. Also, note that the
      amplitudes of the vector $\widetilde{A}$ are equanto $\|A_i\|$,
      and the values stored on the roots of the trees $B_i$ are qual to 
      $\|A_i\|^2$. Hence by a smilar construction for the $m$ roots, we can
      perform the unitary $\widetilde{V}$ efficiently.
  \end{enumerate}
  
\end{proof}

\begin{thm}[\cite{chakraborty2019}]
  Let $A\in\mathbb{R}^{m\times n}$ be a matrix with $A_{ij}\in\mathbb{R}$ being
  the entry of the $i$-th row and the $j$-th column. If $w$ is the number
  of non-zero entries of $A$, then there exits a data structure of size 
  $\mathcal{O}\left(w\log^2(mn)\right)$ that, given the entries $(i,j,A_{ij})$
  in an arbitrary order, stores them such that time taken to store each
  entry of $A$ is $\mathcal{O}\left(\log(mn)\right)$. Once this data structure
  has been initiated with all non-zero entries of $A$, there exists a quantum
  algorithm that can perform the following maps with $\epsilon$-precision in
  $\mathcal{O}(\textrm{\normalfont polylog}(mn/\epsilon))$ time:
  \begin{align*}
    \widetilde{U}&:\ket{i}\ket{0}\mapsto\frac{1}{\|A_{i \cdot}\|}\sum_{j=1}^n
    A_{i,j}\ket{j}=\ket{i,A_i}, \\
    \widetilde{V}&:\ket{0}\ket{j}\mapsto\frac{1}{\|A\|_F}
    \sum_{i=1}^m\|A_{i,\cdot}\|
    \ket{i}\ket{j}=\ket{\widetilde{A},j},
  \end{align*}
  where $\ket{A_{i,\cdot}}$ is the normalized quantum state corresponding to
  the $i$-th row of $A$ and $\ket{\widetilde{A}}$ is a normalized quantum
  state such that $\braket{i|\widetilde{A}}=\|A_{i,\cdot}\|$, i.e. the norm
  of the $i$-th row of $A$.

  In particular, given a vector $\pmb{v}\in\mathbb{R}^{m\times1}$ stored in this
  data structure, we can generate an $\epsilon$-approximation of the
  superposition $\sum_{i=1}^m v_i\ket{i}/\|\pmb{v}\|$ in complexity
  $\textrm{\normalfont polylog}(m/\epsilon)$.
  \end{thm}

The notion of block-encoding was devised as a solution to the problem of
Hamiltonian simulation. Hamiltonian simulation, one of the original motivations
for designing practical quantum computers, may stated as follows: For time
evolution of the wave function $\ket{\psi(t)}$ governed by the Schr{\"o}dinger
equation, that is,
\[
  i\hslash\frac{\textrm{d}}{\textrm{dt}}\ket{\psi(t)}
  = H(t)\ket{\psi(t)}
\]
the Hamiltonian, an operator with units of energy, is $H(t)$. Hamiltionian
simulation is a problem of designing quantum circuit or unitary matrix $U$
consisting of $\textrm{poly}(n,t,1/\epsilon)$ gates such that $\|U-{e^{iHt}}\|\leq
\epsilon$. % Childs - lecture notes
The cost of Hamiltonian simulation depends on the number of qubits
$n$, evolution time $t$, target error $\epsilon$, and access models of
Hamiltonian $H$. While acheiving optimal Hamiltonian simulation by the
process called `Qubitization', Low and Chuang (2017) defined a \emph{standard-form
encoding}, a primitive statement of \emph{block-encoding}. Basically, 
qubitization is a technique of representing Hermitian or subnormalized matrix
as the top-left block of a unitary matrix, that is;
\[
  U=\begin{bmatrix}A/\alpha &\cdot \\ &\cdot &\cdot \end{bmatrix}
\]
where $\cdot$ denotes arbitrary elements of $U$. 
\begin{defn}[Block-encoding] For $A\in\mathbb{C}^{n\times m}, \alpha,\epsilon
  \in\mathbb{R}_{+}$ and $a\in\mathbb{N}$, $(s+a)$-qubit unitary $U$ is an
  $(\alpha,a,\epsilon)$-block-encoding of $A$ if
  \[
    \|A-\alpha(\bra0^{\otimes a}\otimes I)U(\ket0^{\otimes a}\otimes I)\|\leq
    \epsilon.
  \]
\end{defn}
For $n,m\leq 2^s$ we may define an embedding matrix $A_e\in
\mathbb{C}^{2^s\times 2^s}$ such that the top-left block of $A_e$ is $A$ and
all other entries are $0$.

\begin{thm}[\cite{chakraborty2019}]
  Let $A\in\mathbb{C}^{m\times n}$.
  \begin{enumerate}
    \item Fix $p\in [0,1]$. If $A^{(p)}$ and $(A^{(1-p)})^{\dagger}$ are both
      stored in quantum-accessible data structures, then there exist
      unitaries $U_R$ and $U_L$ that can be implemented in time
      $\mathcal{O}(\textrm{\normalfont polylog}(mn/\epsilon))$ such that
      $U_R^{\dagger}U_L$ is a $(\mu_p(A), \lceil\log(n+m+1)\rceil, 
      \epsilon)$-block-encoding of $\bar{A}$.
    \item On th other hand, if $A$ is stored in a quantum-accessible data
      structure, then there exist unitaries $U_R$ and $U_L$ that can
      be implemented in time $\mathcal{O}(\textrm{\normalfont polylog}(mn/\epsilon))$ such
      that $U_R^{\dagger}U_L$ is a $(\|A\|_F, \lceil\log(m+n)\rceil,
      \epsilon)$-block-encoding of $\bar{A}$.
  \end{enumerate}
\end{thm}
\begin{proof}
  For $j\in[m]$, we difne $\ket{\psi_j}$ and $\ket{\phi_j}$ as follows.
  \begin{align*}
    \ket{\psi_j} &= \frac{\sum_{k\in[n]}A^p_{j,k}\ket{j,m+k}}{\sqrt{s_{2p}}(A)}+
    \sqrt{1-\frac{\sum_{k\in[n]}A^{2p}_{j,k}}{s_{2p}(A)}}\ket{j,n+m+1}\\
    \ket{\phi_j} &= \frac{}{}
  \end{align*}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
%                                             %
%          Text for Introduction              %
%                                             %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Introduction is here


\section{Main results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
%                                             %
%          Text for main results              %
%                                             %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Main results are here

\begin{thm}[Pan and Zhang {\cite[p. 682 (1.5)]{bc}}]
Theorem is here
\end{thm}
\begin{proof}
Proof is here ~\cite[Proposition 1.4]{cp}
\end{proof}

\begin{lem}[Yun \cite{pang}]
Lemma is here
\end{lem}
\begin{proof}
Proof is here
\end{proof}

\begin{cor}[\cite{pang}]
Corollary is here
\end{cor}

\begin{defn}
Definition is here
\end{defn}

\begin{rem}
Remark is here
\end{rem}


\bigskip
{\bf Conflicts of interest} : {Declare conflicts of interest or state ``The authors declare no conflict of interest.'' Authors must identify and declare any personal circumstances or interest that may be perceived as inappropriately influencing the representation or interpretation of reported research results.} 

%% Optional-------------------------------------------------------------
\bigskip
{\bf Data availability} : {In this section, please provide details regarding where data supporting reported results can be found, including links to publicly archived datasets analyzed or generated during the study. If the study did not report any data, you might add ``Not applicable'' here.} 
%-----------------------------------------------------------------------

%% Optional-------------------------------------------------------------
\bigskip
{\bf Acknowledgments} : {In this section you can acknowledge any support given which is not covered by the author contribution or funding sections.}
%-----------------------------------------------------------------------


\bigskip
\bibliography{ref}
\bibliographystyle{amsplain}
\begin{thebibliography}{0}
%bib files are not available.-------------------------

%ref-book----------------------------------------------
\bibitem{bc} 
C. Baiocchi and A. Capelo, 
{\it Variational and Quasi Variational Inequalities}, 
J. Wiley and Sons, 
New York, 
1984.

%ref-journal-------------------------------------------
\bibitem{chakraborty2019}
Chakraborty, Gily{\'en} and Jeffery. {\it The Power of Block-Encoded Matrix
Powers}, ICALP {\bf 132} (2019), 33:1-33:14.

\bibitem{kerenidis2020}
Kerenidis, Iordanis and Prakash, Anupam. {\it Quantum gradient descent for
linear systems and leaste squares}, Phys.Rev.A {\bf 2} (2020), 022316.

\bibitem{tang2023}
Tang, Ewin, and James Lee. {\it Quantum Machine Learning Without Any Quantum},
ProQuest Dissertations and Theses, University of Washington (2023), 21-22.

\bibitem{cp} 
D. Chan and J.S. Pang, 
{\it The generalized quasi variational inequality problems}, 
Math. Oper. Research 
{\bf 7} (1982), 
211-222.

\bibitem{belly} 
C. Belly, 
{\it Variational and Quasi Variational Inequalities}, 
J. Appl. Math. and Computing 
{\bf 6} (1999), 
234-266.

\bibitem{pang} 
D. Pang, 
{\it The generalized quasi variational inequality problems}, 
J. Appl. Math. and Computing 
{\bf 8} (2002), 
123-245.



\bigskip
\bigskip

%Type a brief sketch of biography and research interests not exceeding 85 words.------------------------
%The following is a sample biography

\pn {\bf 1st Author name} received M.Sc. from Seoul National University and Ph.D. at University of Minnesota. 
Since 1992 he has been at Chungnam National University. 
His research interests include numerical optimization and biological computation.

\medskip
\pn % Affiliations / Addresses
Department of Mathematics, Chungnam National University, Daejeon 305-764, Korea. 
\pn{\tt e-mail: soh@cnu.ac.kr}

\bigskip
\pn {\bf 2nd Author name} received M.Sc. from Kyungpook National University, and Ph.D. from Iowa State University. 
He is currently a professor at Chungbuk National University since 1991. 
His research interests are computational mathematics, iterative method and parallel computation.

\medskip
\pn % Affiliations / Addresses
Department of Mathematics, College of Natural Sciences, Chungbuk National University, Cheongju 361-763, Korea.
\pn{\tt e-mail: gmjae@chungbuk.ac.kr}



\end{thebibliography}

\end{document}
