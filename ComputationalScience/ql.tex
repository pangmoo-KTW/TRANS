%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                   %
%                      JAMI - LaTeX format                          %
%                                                                   %
%     E-mail address  : ryoocs@hnu.kr                               %
%                                                                   %
%                                                                   %
%                                                                   %
%   We are accepting manuscripts with AMSTeX or LaTeX versions      %
%   through E-mail.                                                 %
%                                                                   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[10pt,twoside,reqno]{amsart} %For LaTeX2e users

%\documentstyle[10pt,twoside]{amsart} %For old version of Latex users

\allowdisplaybreaks
\usepackage{amsmath,amstext,amssymb,braket}
\usepackage{graphicx,forest}
\usetikzlibrary{arrows.meta}

\textwidth 12.2 cm
\textheight 19.3 cm
\oddsidemargin 1.2cm
\evensidemargin 1.2cm
\calclayout

\setcounter{page}{1}
%
\makeatletter
\renewcommand{\@seccntformat}[1]{\bf\csname the#1\endcsname. }
\renewcommand{\section}{\@startsection{section}{1}
   \z@{.7\linespacing\@plus\linespacing}{.5\linespacing}
   {\normalfont\upshape\bfseries\centering}}
%\@addtoreset{thm}{section} \@addtoreset{rem}{section}
\renewcommand{\@biblabel}[1]{\@ifnotempty{#1}{#1.}}
\makeatother
%
\renewcommand{\refname}{\sc References}
%
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{pro}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{exa}[thm]{Example}
\newtheorem{defn}[thm]{Definition}
\newtheorem{rem}{Remark}[section]

\def\pn{\par\noindent}


\begin{document}

\leftline{\scriptsize \it  J. Appl. Math. {$\&$}
Informatics Vol. {\bf 4x}(2023), No. x, pp. xx - xx   }
\vspace{-0.15cm}
%\leftline{\footnotesize Website: http://www.jami.or.kr}
\leftline{\footnotesize https://doi.org/10.14317/jami.201x.xxx}



\vspace{1.3cm}

\title
{ %Full title of the paper
A Survey on alternative quantum input models$^\dagger$  
}

\author
{ %Firstname Lastname, Firstname Lastname
  Hyeonmin Roh$^*$, Taewon Kim$^{**}$ 
}

\thanks{ {\scriptsize  Received     ,     .  Revised ,   .    Accepted     ,   . \enskip $^*$Corresponding author.}\\
\indent{\scriptsize $^\dagger$%funding-------------------------------------------------------------------
{Please add: ``This research received no external funding'' or ``This research was funded by NAME OF FUNDER grant number XXX.'' and  and ``The APC was funded by XXX''. Check carefully that the details given are accurate and use the standard spelling of funding agency names, any errors may affect your future funding.}
Example:This work was supported by the research grant of the University}\\
\indent{\scriptsize $\copyright$ 2023 KSCAM}}


\maketitle


\begin{abstract}
  This paper provides an expository expansion to an open problem in quantum
  machine learning; whether there are alternative data structures that
  prevent efficient classical counterparts for quantum machine learning 
  algorithms. 
  %The main goal of this paper is to formulate a quantum data structure that
  %prevents efficient classical counterparts of Quantum machine learning
  %algorithms. Since such prevention have been an open problem in quantum 
  %machine learning theory, we provide some general properties regarding the
  %problem, focusing on norm variation.
  %not exceed 160 words and must contain Main Facts 

\vskip 0.4 true cm


\noindent
 AMS Mathematics Subject Classification : 65H05, 65F10.

\noindent 
{\it Key words and phrases } : %keyword 1, keyword 2, keyword 3.

\end{abstract}


\pagestyle{myheadings}
\markboth{\centerline {\scriptsize  the names of the authors  }}
         {\centerline {\scriptsize  title of paper  }}


\bigskip
\section{Introcution}
Quantum machine learning (QML) was activated by the HHL algorithm
\cite{harrow2009} that approximately solves a system of linear equations in a
logarithmic time. However, as Aaronson \cite{aaronson2015} critiqued, HHL and
other QML algorithms involved quantum advantageous \emph{input assumptions} 
or \emph{data structures}. Critically, Tang \cite{tang2019} introduced
\emph{dequantization}, a method of providing efficient classical counterparts
for large amount of QML algorithms by randomized-linear algebraic exploitations of
quantum-advantageous assumptions, hence demystifying claimed exponential
speedups of QML algorithms. This paper focus on the problem of constructing
data structrues that prevent dequantization, that is, an open problem stated
in Tang's thesis \cite{tang2023} with implicit examples by Chakraborty, Gily\'en 
and Jeffry \cite{chakraborty2019} and Kerenidis and Prakash \cite{kerenidis2020}.

\section{Preliminaries}

By practical or industrial reasons, the majority of data given for QML are
classical.
\begin{defn}
  Classical data is an element of $n$-fold Cartesian product $\{0,1\}^n$.
\end{defn}

To utillize classical data within a quantum computer, there must be an efficient
way or a structure to prepare those data inputs into quantum states, where
quantum states are defined as follows.

\begin{defn}
  For $a_x\in\mathbb{C}$, if $\sum_x|a_x|^2=1$, sum of $\ell_2$-normalized
  vectors in a complex vector space
  \[
    \ket{\psi} = \sum_{x\in\{0,1\}^n}a_x\ket{x}
  \]
  is the state of $n$ qubits.
\end{defn}

We simply assumme that such efficient preperation by supposing Quantum Random
Access Memory (QRAM), a classical memory that can be accessed by quantum
algorithms. Incidentally, QRAM is quite a broad term
as noted in survey of Jaques and Rattew \cite{jaques2023}, but following
abstraction might suffice for our discussion. Beforehand, it is useful to
introduce following abbreviation
\[
  \ket{\psi}\otimes\ket{\phi} = \ket{\psi}\ket{\phi} = \ket{\psi, \phi}
\]
since $\ket{\;\cdot\;}$ denotes a column vector.

\begin{defn}
  For classical data $t_i\in\{0,1\}^n$, existence of QRAM is an assumption
  that there exist unitaries of the form
  \[
    U\ket{i,0}=\ket{i,t_i}
  \]
  and such action of $U$ requires $\mathcal{O}(\textrm{polylog}(n))$ time.
\end{defn}

Classical data $t_i$ constitues a classical memory $T$. Register of $\ket{i}$
is called the address register. Time complexity of $U$ expressed in big-oh
notation means that there exists constants $c$ and $n_0$ both equal or greater
than $0$ such that $T(n)$, a time function of $U$ for $n$, is equal or less than
the polylogarithmic function of $n$ multiplied by $c$ for all $n\geq n_0$.
Another useful notation in algorithmic analysis is 
$\widetilde{\mathcal{O}}(f(n))$, shorthand for $\mathcal{O}(g(n)\log^k g(n))$.

\section{Quantum accesibble classical data structure}

QRAM enables input models or \emph{data structures} for processing matrix
input in a quantum adventageous way. We restate such data structure utilized
in the quantum recommendation algorithm by Kerenidis \cite{kerenidis2017},
first QML algorithm to be dequantized by Tang \cite{tang2019}. In advance,
we check state preparation method by Grover and Rudolph \cite{grover2002}.

\begin{cor}
  Let a probability distribution $\{p_i\}$ such that $p_i^{(m)}$ is the
  probability for the random variable $x$ to lie in the $i$th region, and 
  $p_s^{(m)}$ is the probability for $x$ to lie in $s$th region. For an
  orthonormal state $\ket{i}$, let a $m$-qubit state as follows
  \[
    \ket{\psi_m} = \sum_{i=0}^{2^m-1}\sqrt{p_i^{(m)}}\ket{i}.
  \]
  Then, we can get the mapping of
  \[
    \ket{\psi_{m+1}}=\sum_{i=0}^{2^{m+1}-1}\sqrt{p_i^{(m+1)}}\ket{i}.
  \]
\end{cor}
\begin{proof}
  Let $n=\log N$ for the total number of points $N$ to discretize the
  distribution $p(x)$. That is, we divide the distribution with $2^m$ of regions
  for some $m$. We subdivide these $2^m$ regions to yield a $2^{m+1}$
  region discretization of $p(x)$. 
  
  First, we define the left and right boundaries of region $i$ as
  $x_L^i$ and $x_R^i$  with the function
  \[
    f(i)=\frac{\int_{x_L^i}^{(x_R^i-x_L^i)/2}p(x)dx}{\int_{x_L^i}^{x_R^i}p(x)dx}.
  \]
  That is, for $x$ in the region $i$, the probability of $x$ also lying
  in the left half of this region. Since an integral on $p(x)$ can be
  classicaly computed efficiently, we take an ancillia register initially
  in the state $\ket{0\ldots 0}$ and construct a circuit which efficiently
  performs the computation
  \[
    \sqrt{p_i^{(m)}}\ket{i,0\cdots0}\mapsto\sqrt{p_i^{(m)}}\ket{i,\theta_i)}
  \]
  where $\theta_i\equiv \arccos\sqrt{f(i)}$. Then, by a controlled rotation
  of angle $\theta_i$ on the $m+1$'th qubit, we have
  \[
    \sqrt{p_i^{(m)}}\ket{i,\theta_i,0}\mapsto
    \sqrt{p_i^{(m)}}\ket{i,\theta_i}(\cos\theta_i\ket0+\sin\theta_i\ket1)
  \]
  where we can uncompute the register containing $\ket{\theta_i}$ with
  \[
    \sqrt{p_i^{(m)}}\ket{i}\mapsto\sqrt{\alpha_i}\ket{i,0}+
    \sqrt{\beta_i}\ket{i,1}
  \]
  where $\alpha$ and $\beta$ are the probability for $x$ to lie in the left
  or right half of the region $i$, respectivly. 
  We apply the mapping above for $m$-qubit states given as
  \[
    \ket{\psi_m} = \sum_{i=0}^{2^m-1}\sqrt{p_i^{(m)}}\ket{i}.
  \]
  Then, we get $\sqrt{\psi_{m_1}}$ as desired.
\end{proof}
\begin{lem}
  Given a certain probability distribution $\{p_i\}$, we can efficiently
  construct a superposition of
  \[
    \ket{\psi(\{p_i\})} = \sum_i\sqrt{p_i}\ket{i}.
  \]
\end{lem}
\begin{proof}
  By repeating the cororally above until $m=n$, we can efficiently construct
  a superposition as desired.
\end{proof}

This result, variable by construction details, is used in the data structure
below to to efficiently perform $\widetilde{U}$ and $\widetilde{V}$.

\begin{thm}[\cite{kerenidis2017} Theorem 15]
  For a real matrix $A\in\mathbb{R}^{m\times n}$, let $(i,j,A_{ij})$ be given
  data. If we assume QRAM, then, there exists a data structure
  representable by binary search trees to store the matrix $A$ with
  following properties:
  \begin{enumerate}
    \item The size of the data structure is $\mathcal{O}(w \log^2(mn))$ where
    $w$ is the number of data entries already in the tree.
  \item The time to store a new data $(i,j,A_{ij})$ is $\mathcal{O}(\log^2 (mn))$.
  \item There exists a quantum algorithm that takes $\textrm{\normalfont 
    polylog}(mn)$ time to perform the mapping
    \[
      \widetilde{U}:\ket{i,0}\rightarrow \ket{i, A_i}
    \]
    and for $\widetilde{A}\in\mathbb{R}^m$ with entries $\widetilde{A_i}=\|A_i\|$,
    \[
      \widetilde{V}:\ket{0,j}\rightarrow\ket{\widetilde{A},j}.
    \]
  \end{enumerate}
\end{thm}
\begin{proof}
  The data structure consits $m$ binary trees $B_i$, where $i\in[m]$. 
  Leaf node is created or updated by the arrival of new entry $(i,j,A_{ij})$,
  storing the value $A_{ij}^2$, where internal node $v$ stores the sum of the
  values of all leaves in the subtree rooted at $v$. Hence, the value stored
  at the root is $\|A_i\|^2$.
\begin{figure}[h]
  \begin{forest}
    for tree={
      edge={-{Stealth[]}},
    }
    [$\|A_i\|^2$
      [$\|A_{i1}\|^2+\|A_{i2}\|^2$
        [$\|A_{i1}\|^2$
          [$A_{i1}^2$
          ]
        ]
        [$\|A_{i2}\|^2$
          [$A_{i2}^2$
          ]
        ]
      ]
      [$\|A_{i3}\|^2+\|A_{i4}\|^2$
        [$\|A_{i3}\|^2$
          [$A_{i3}^2$
          ]
        ]
        [$\|A_{i4}\|^2$
          [$A_{i4}^2$
          ]
        ]
      ]
    ]
  \end{forest}
  \caption{example for $A^{i\times 4}$}
\end{figure}

  The depth of the tree is at most $\lceil\log n\rceil$ for most $n$ leaves,
  which is the number of updates required for a new entry. If we store
  each tree sorted as ordered list, update node address retrival time and
  bits required for memory would be $\mathcal{O}(\log mn)$. Thus, the size of the
  data structure is $\mathcal{O}(w\log^2(mn))$ and the time to store a new
  entry is $\mathcal{O}(\log^2(mn))$. 
\end{proof}
This data structure constitues an array of $m$  binary trees. The value
stored at the root is $\|A_i\|^2$ for $i\in[m]$, and depth of each tree is
at most $\lceil\log n\rceil$. For a fair evaluation of quantum speedup
provided by such QRAM-dependant data stucture, dequantization starts
from constructing equivalent binary search tree with only a polynomial
slowdown.
\begin{defn}[\cite{tang2023} Definition 4.1]
  For all $i\in[n]$, if we can query for $v(i)$, we have \emph{query access}
  to a vector $v\in\mathbb{C}^n$, denoted by $Q(v)$. For all 
  $(i,j)\in[m]\times[n]$, if we can query for $A_{ij}$, we have $Q(A)$ to
  a matrix $A\in\mathbb{C}^{m\times n}$. Time cost of such query is denoted
  by $q(v)$ and $q(A)$, respectively.
\end{defn}
\begin{defn}[\cite{tang2023} Definition 4.2]
  For a vector $v\in\mathbb{C}^n$, we have \emph{sampling and query access} to
  $v$, denoted by $SQ(v)$, if we can:
  \begin{enumerate}
    \item have query access to $v$;
    \item obtain independent samples $i\in[n]$ following the distribution
      $\mathcal{D}_v\in\mathbb{R}^n$ with $\mathcal{D}_v(i):=|v(i)|^2/\|v\|^2$;
    \item have query access to $\|v\|$.
  \end{enumerate}
  Cost of entry querying, index sampling, norm querying, are denoted as
  $q(v),s(v),$ and $n(v)$, respectively. Also, let $sq(v):=\max(q(v),s(v),n(v))$.
\end{defn}
Samples obtained from sampling and query access are analogue to the quantum
state $\ket{v} := 1/\|v\|\sum v_i\ket{i}$ in the computational basis. Such
sampling and query access may be generalized by some oversampling rate.
\begin{defn}
  For $v\in\mathbb{C}^n$ and $\phi\geq1$, we have
  $\widetilde{v}\in\mathbb{C}^n$ if $\|\widetilde{v}\|^2=\phi\|v\|^2$ and
  $|\widetilde{v}_i|^2\geq |v_i|^2$ for all $i\in[n]$.
\end{defn}
\begin{defn}[\cite{tang2023} Definition 4.3]
  For $v\in\mathbb{C}^n$ and $\phi\geq1$, if $Q(v)$ and 
  $SQ(\widetilde{v})$ for $\widetilde{v}\in\mathbb{C}^n$, we have 
  $\phi$-\emph{oversampling and query access to $v$} or $SQ_{\phi}(v)$. Also,
  \begin{align*}
    s_{\phi}(v) := s(\widetilde{v}),\;
    q_{\phi}(v) := q(\widetilde{v}),\;
    n_{\phi}(v) := n(\widetilde{v}),\;
    sq_{\phi}(v) := \max(s_{\phi}(v),q_{\phi}(v),n_{\phi}(v)).
  \end{align*}
\end{defn}

\begin{figure}[h]
  \begin{forest}
    for tree={
      edge={-{Stealth[]}},
    }
      [$\|\widetilde{A}\|^2$
        [$\|\widetilde{A_1}\|^2$
        [$\|\widetilde{A_{11}}\|^2+\|\widetilde{A_{12}}\|^2$
          [$\|\widetilde{A_{11}}\|^2$
            ]
            [
            $\|\widetilde{A_{12}}\|^2$
            ]
          ]
          [$\|\widetilde{A_{13}}\|^2+\|\widetilde{A_{14}}\|^2$
          [$\|\widetilde{A_{13}}\|^2$
            ]
            [$\|\widetilde{A_{14}}\|^2$
            ]
          ]
        ]
        [$\|\widetilde{A_2}\|^2$
        [$\|\widetilde{A_{21}}\|^2+\|\widetilde{A_{22}}\|^2$
          [$\|\widetilde{A_{21}}\|^2$
            ]
            [$\|\widetilde{A_{22}}\|^2$
            ]
          ]
          [ $\|\widetilde{A_{23}}\|^2+\|\widetilde{A_{24}}\|^2$
          [$\|\widetilde{A_{23}}\|^2$
            ]
            [$\|\widetilde{A_{24}}\|^2$
            ]
          ]
        ]
      ]
  \end{forest}
  \caption{example of a $\phi$-sampling and qeury access data structure}
\end{figure}
Note that $SQ_{\phi}(v)$ constructs an identical tree structure to the one
from QRAM. So, we can dequantize whenever QML algorithm relies on QRAM
based data structure. 
\section{Alternative Data Structures}
However, there have been variations for such definitions of QRAM, which might
prevent dequantization. We first present such variant with general approach,
then with more concrete form of presentation by \emph{block-encoding}.
Theorem below constructs a more efficient variant of QRAM, where the memory
requirement \cite{kerenidis2020} is $\widetilde{\mathcal{O}}(mn)$ and time cost
of update, insertion, or deletion for a single entry is
$\mathcal{O}(\textrm{polylog}(n))$.
of art. 
\begin{thm}[\cite{kerenidis2020} Theorem IV.2]
  Let $M=\max_{i\in[m]}\|a_i\|^2$ and $A\in\mathbb{R}^{m\times n}$. There
  eixsts an efficient QRAM data structure for storing matrix entries
  $(i,j,a_{ij})$ such that access to this data structure allows a quantum
  algorithm to implement following unitary in time 
  $\widetilde{\mathcal{O}}(\log (mn))$.
  \[
    U\ket{i,0^{\lceil\log(n+1)\rceil}} = \ket{i}\frac{1}{\sqrt{M}}
    \left(\sum_{j\in[n]}a_{ij}\ket{j}+(M-\|a_i\|^2)^{1/2}\ket{n+1}\right).k
  \]
\end{thm}
Before heading to the proof, it is helpful to understand utility of $M$.
\begin{defn}
  The normalized vector state corresponding to vector $x\in\mathbb{R}^n$ and
  $M\in\mathbb{R}$ such that $\|x\|^2\leq M$ is the quantum state
  \[
    \ket{\bar{x}} = \frac{1}{\sqrt{M}}
    \left(\sum_{i\in[n]}x_i\ket{i}+(M-\|x\|^2)^{1/2}\ket{n+1}\right).
  \]
\end{defn}
So the key variation is the norm in the input state.
\begin{proof}
  $m$ binary trees $B_i$ $\longrightarrow$ use {\bfseries rotation}
  \begin{align*}
    \bullet\\\bullet \\\bullet
  \end{align*}
\end{proof}
Now we define the notion of block-encoding to clarify the prevention
of result above. Block-encdoing was devised during a optimal
solution of Hamiltonian simulation probem, \cite{low2019} originally termed
as `qubitization'. Simply put, block-encoding is a technique of representing
Hermitian or subnormalized matrix as the top-left block of a unitary matrix, 
that is;
\[
  U=\begin{bmatrix}A/\alpha &\cdot \\ \cdot &\cdot \end{bmatrix}
\]
where $\cdot$ denotes arbitrary elements of $U$. 
\begin{defn}[Gily\'en 2019] For $A\in\mathbb{C}^{n\times m}, \alpha,\epsilon
  \in\mathbb{R}_{+}$ and $a\in\mathbb{N}$, $(s+a)$-qubit unitary $U$ is an
  $(\alpha,a,\epsilon)$-block-encoding of $A$ if
  \[
    \|A-\alpha(\bra0^{\otimes a}\otimes I)U(\ket0^{\otimes a}\otimes I)\|\leq
    \epsilon.
  \]
\end{defn}
For $n,m\leq 2^s$ we may define an embedding matrix $A_e\in
\mathbb{C}^{2^s\times 2^s}$ such that the top-left block of $A_e$ is $A$ and
all other entries are $0$.

\begin{thm}[Chakraborty, 2019, Lemma 25]
  Let $A\in\mathbb{C}^{m\times n}$.
  \begin{enumerate}
    \item Fix $p\in [0,1]$. If $A^{(p)}$ and $(A^{(1-p)})^{\dagger}$ are both
      stored in quantum-accessible data structures, then there exist
      unitaries $U_R$ and $U_L$ that can be implemented in time
      $\mathcal{O}(\textrm{\normalfont polylog}(mn/\epsilon))$ such that
      $U_R^{\dagger}U_L$ is a $(\mu_p(A), \lceil\log(n+m+1)\rceil, 
      \epsilon)$-block-encoding of $\bar{A}$.
    \item On th other hand, if $A$ is stored in a quantum-accessible data
      structure, then there exist unitaries $U_R$ and $U_L$ that can
      be implemented in time $\mathcal{O}(\textrm{\normalfont polylog}(mn/\epsilon))$ such
      that $U_R^{\dagger}U_L$ is a $(\|A\|_F, \lceil\log(m+n)\rceil,
      \epsilon)$-block-encoding of $\bar{A}$.
  \end{enumerate}
\end{thm}

\begin{thm}
  Chakraborty2019 
\end{thm}

\begin{thm}
  main result 
\end{thm}

\section{Examples and Applications}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
%                                             %
%          Text for Introduction              %
%                                             %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
%                                             %
%          Text for main results              %
%                                             %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\bigskip
{\bf Conflicts of interest} : {Declare conflicts of interest or state ``The authors declare no conflict of interest.'' Authors must identify and declare any personal circumstances or interest that may be perceived as inappropriately influencing the representation or interpretation of reported research results.} 

%% Optional-------------------------------------------------------------
\bigskip
{\bf Data availability} : {In this section, please provide details regarding where data supporting reported results can be found, including links to publicly archived datasets analyzed or generated during the study. If the study did not report any data, you might add ``Not applicable'' here.} 
%-----------------------------------------------------------------------

%% Optional-------------------------------------------------------------
\bigskip
{\bf Acknowledgments} : {In this section you can acknowledge any support given which is not covered by the author contribution or funding sections.}
%-----------------------------------------------------------------------


\bigskip
%bib files are not available.-------------------------
\bibliographystyle{amsplain}
\begin{thebibliography}{0}

%ref-book----------------------------------------------
\bibitem{bc} 
C. Baiocchi and A. Capelo, 
{\it Variational and Quasi Variational Inequalities}, 
J. Wiley and Sons, 
New York, 
1984.

%ref-journal-------------------------------------------
\bibitem{grover2002}
L. Grover and T. Rudolph,
{\it Creating superpositions that correspond to efficiently integrable
probability distributions,"},
arXiv preprint quant-ph/0208112, (2002).

\bibitem{harrow2009}
A. W. Harrow, A. Hassidim and S. Lloyd,
{\it Quantum algorithm for linear Systems of equations},
Phys. Rev. Lett
{\bf 103} (2009),
150502.

\bibitem{aaronson2015}
S. Aaronson,
{\it Read the fine print},
Nature Phys
{\bf 11} (2015),
291-293.

\bibitem{kerenidis2017}
I. Kerenidis and A. Prakash,
{\it Quantum Recommendation Systems},
ITCS
{\bf 67} (2017),
49:1--49:21.

\bibitem{babbush2018}
R. Babbush, C. Gidney, B. Dominic, N. Weibe, J. McClean, A. Paler, A. Fowler
and H. Neven,
{\it Encoding Electronic Spectra in Quantum Circuits with Linear $T$ Complexity}
Phys. Rv.
{\bf 8} (2018),
041015.

\bibitem{low2019}
H. Low and I. Chuang,
{\it Hamiltonian Simulation by Qubitization},
Quantum
{\bf 3} (2019),
163.

\bibitem{chakraborty2019}
Chakraborty, Gily{\'en} and Jeffery. {\it The Power of Block-Encoded Matrix
Powers}, ICALP {\bf 132} (2019), 33:1-33:14.

\bibitem{tang2019}
E. Tang. {\it A Quantum-Inspired Classical Algorithm for Recommendation Systems},
Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing (2019),
217--228.

\bibitem{kerenidis2020}
Kerenidis, Iordanis and Prakash, Anupam, 
{\it Quantum gradient descent for linear systems and leaste squares}, 
Phys.Rev.A {\bf 2} (2020), 
022316.

\bibitem{jaques2023}
S. Jaques and A. Rattew,
{\it QRAM: A Survey and Critique},
arXiv: 2305.10310 [quant-ph] (2023).

\bibitem{tang2023}
E. Tang,
{\it Quantum Machine Learning Without Any Quantum},
Ph.D. diss, University of Washington (2023).

\bibitem{cp} 
D. Chan and J.S. Pang, 
{\it The generalized quasi variational inequality problems}, 
Math. Oper. Research 
{\bf 7} (1982), 
211-222.

\bibitem{belly} 
C. Belly, 
{\it Variational and Quasi Variational Inequalities}, 
J. Appl. Math. and Computing 
{\bf 6} (1999), 
234-266.

\bibitem{pang} 
D. Pang, 
{\it The generalized quasi variational inequality problems}, 
J. Appl. Math. and Computing 
{\bf 8} (2002), 
123-245.



\bigskip
\bigskip

%Type a brief sketch of biography and research interests not exceeding 85 words.------------------------
%The following is a sample biography

\pn {\bf 1st Author name} received M.Sc. from Seoul National University and Ph.D. at University of Minnesota. 
Since 1992 he has been at Chungnam National University. 
His research interests include numerical optimization and biological computation.

\medskip
\pn % Affiliations / Addresses
Department of Mathematics, Chungnam National University, Daejeon 305-764, Korea. 
\pn{\tt e-mail: soh@cnu.ac.kr}

\bigskip
\pn {\bf 2nd Author name} received M.Sc. from Kyungpook National University, and Ph.D. from Iowa State University. 
He is currently a professor at Chungbuk National University since 1991. 
His research interests are computational mathematics, iterative method and parallel computation.

\medskip
\pn % Affiliations / Addresses
Department of Mathematics, College of Natural Sciences, Chungbuk National University, Cheongju 361-763, Korea.
\pn{\tt e-mail: gmjae@chungbuk.ac.kr}



\end{thebibliography}

\end{document}
