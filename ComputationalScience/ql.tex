%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                   %
%                      JAMI - LaTeX format                          %
%                                                                   %
%     E-mail address  : ryoocs@hnu.kr                               %
%                                                                   %
%                                                                   %
%                                                                   %
%   We are accepting manuscripts with AMSTeX or LaTeX versions      %
%   through E-mail.                                                 %
%                                                                   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[10pt,twoside,reqno]{amsart} %For LaTeX2e users

%\documentstyle[10pt,twoside]{amsart} %For old version of Latex users

\allowdisplaybreaks
\usepackage{amsmath,amstext,amssymb,braket}
\usepackage{graphicx,forest}
\usetikzlibrary{arrows.meta}

\textwidth 12.2 cm
\textheight 19.3 cm
\oddsidemargin 1.2cm
\evensidemargin 1.2cm
\calclayout

\setcounter{page}{1}
%
\makeatletter
\renewcommand{\@seccntformat}[1]{\bf\csname the#1\endcsname. }
\renewcommand{\section}{\@startsection{section}{1}
   \z@{.7\linespacing\@plus\linespacing}{.5\linespacing}
   {\normalfont\upshape\bfseries\centering}}
%\@addtoreset{thm}{section} \@addtoreset{rem}{section}
\renewcommand{\@biblabel}[1]{\@ifnotempty{#1}{#1.}}
\makeatother
%
\renewcommand{\refname}{\sc References}
%
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{pro}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{exa}[thm]{Example}
\newtheorem{defn}[thm]{Definition}
\newtheorem{rem}{Remark}[section]

\def\pn{\par\noindent}


\begin{document}

\leftline{\scriptsize \it  J. Appl. Math. {$\&$}
Informatics Vol. {\bf 4x}(2023), No. x, pp. xx - xx   }
\vspace{-0.15cm}
%\leftline{\footnotesize Website: http://www.jami.or.kr}
\leftline{\footnotesize https://doi.org/10.14317/jami.201x.xxx}



\vspace{1.3cm}

\title
{ %Full title of the paper
Variation in norms of quantum input models$^\dagger$  
}

\author
{ %Firstname Lastname, Firstname Lastname
  Hyeonmin Roh$^*$, Taewon Kim$^{**}$ 
}

\thanks{ {\scriptsize  Received     ,     .  Revised ,   .    Accepted     ,   . \enskip $^*$Corresponding author.}\\
\indent{\scriptsize $^\dagger$%funding-------------------------------------------------------------------
{Please add: ``This research received no external funding'' or ``This research was funded by NAME OF FUNDER grant number XXX.'' and  and ``The APC was funded by XXX''. Check carefully that the details given are accurate and use the standard spelling of funding agency names, any errors may affect your future funding.}
Example:This work was supported by the research grant of the University}\\
\indent{\scriptsize $\copyright$ 2023 KSCAM}}


\maketitle


\begin{abstract}
  The main goal of this paper is to formulate a quantum data structure that
  prevents efficient classical counterparts of Quantum machine learning
  algorithms. Since such prevention have been an open problem in quantum 
  machine learning theory, we provide some general properties regarding the
  problem, focusing on norm variation.
  %not exceed 160 words and must contain Main Facts 

\vskip 0.4 true cm


\noindent
 AMS Mathematics Subject Classification : 65H05, 65F10.

\noindent 
{\it Key words and phrases } : %keyword 1, keyword 2, keyword 3.

\end{abstract}


\pagestyle{myheadings}
\markboth{\centerline {\scriptsize  the names of the authors  }}
         {\centerline {\scriptsize  title of paper  }}


\bigskip
\section{Introcution}
Quantum machine learning (QML) is a field of study subsequent
to HHL algorithm \cite{harrow2009} that approximately solves a system of linear
equations in a logarithmic time. However, there have been critiques 
\cite{aaronson2015} on input model assumptions or quantum data structures
utilized in QML algorithms. Furthermore, Tang \cite{tang2019} introduced 
\emph{dequantization}, a method that provides efficient classical counterparts
on classical data for QML algorithms by randomized-linear algebraic exploitations
of quantum-advantageous assumptions. Currently, preventing dequantization
is one of open problems \cite{tang2023} in QML theory.

%All recognized QML techniques rooted in linear algebra fall under the umbrella
%of Quantum Singular Value Transformation (QSVT), serving as a unifying framework
%for quantum algorithms. QSVT is categorized based on the assumptions of the input
%models. These assumptions revolve around whether the inputs for QML are sparse or
%low-rank. While sparse-access input models are known for providing exponential
%speedups, dequantization targets low-rank input models where classical data, 
%without strict limitations, can be applied.

As in ML, input data models are classical for QML usually. To make classical
data compatible with QML algorithms, such data need to be efficiently transformed
into quantum states. Simple solution is to assume the existence of Quantum 
Random Access Memory (QRAM), a quantum counterpart to classical RAM, capable of
storing $n$ bits of data and querying these data in superposition within a time
complexity of polylog$(n)$. Dequantization essentially involves
mimicking QRAM for classical computers by assuming an input model of sampling
and query access to a vector. This assumption allows for a fair comparison
between quantum and classical machine learning methodologies.

The outcomes of dequantization establish a boundary for our comprehension of QML
algorithms and their constraints. Consequently, a significant unresolved issue
in QML pertains to identifying alternative methods for constructing data 
structures that prevent dequantization. This issue is the focal point, 
considering its fundamental unit termed 'Block-encoding.' The objective is to
formally define an alternative data structure implicitly suggested by Kerenidis
and Prakash, and Chakraborty, Gily√©n, and Jeffery, and provide general exposition
to the question of what properties let QML algorithms to be dequantized.

\section{Nomenclature}
\section{Quantum accesibble classical data structure}
Regarding QML and dequantization, notion such as Quantum accesibble classical
memory or Quantum Read-Only Memory (QROM \cite{babbush2018}) are termed simply
`QRAM' because most data used in ML are classical. 

\begin{defn}[\cite{jaques2023} Definition 1]
  For a table of data $T\in\{0,1\}^N$, 
  QRAM is a collection of unitaries $U_Q(T)$,
  such that for all states $\ket{i}$ in the computational basis
  where $0\leq i\leq N-1$, 
  \[
    U_Q(T)\ket{i}\ket{0} = \ket{i}\ket{T_i}.
  \]
\end{defn}
Note that $U_Q(T)$ is unitary. By linearity, the number of qubits during access
by superposition is $\lceil\log^N\rceil$. Hence, assume that query of the
form $\ket{i}\ket{0}\rightarrow\ket{i}\ket{T_i}$ requires 
$\mathcal{O}(\textrm{polylog})$ time. Following is an input model or a data
structure upon such QRAM, employed in quantum recommendation algorithm.
\begin{thm}[\cite{kerenidis2017} Theorem 15]
  Let $A\in\mathbb{R}^{m\times n}$ be a matrix. Let $(i,j,A_{ij})$ be 
  entries arriving in the system in a arbitrary order, and $w$ be the
  number of entries already in the system. Then, there exists a data structre
  to store the matrix $A$ with following properties:
  \begin{enumerate}
    \item The size of the data structure is $\mathcal{O}(w\log^2(mn))$.
    \item The time to store a new entry $(i,j,A_{ij})$ is 
      $\mathcal{O}(\log^2(mn))$.
    \item Corresponding to the rows of the matrix currently stored,
      a quantum algorithm that has quantum access to the data structure
      can perform the mapping 
      \[
        \widetilde{U}:\ket{i}\ket{0}\rightarrow\ket{i}\ket{A_i},
      \]
      and for $\widetilde{A}\in\mathbb{R}^m$ with entries 
      $\widetilde{A_i}=\|A_i\|$ and $j\in[n]$,
      \[
        \widetilde{V}:\ket{0}\ket{j}\rightarrow\ket{\widetilde{A}}\ket{j}.
      \]
      This quantum algorithm takes $\textrm{\normalfont polylog}(mn)$ time.
  \end{enumerate}
\end{thm}
This data structure is an array of $m$  binary trees. The value
stored at the root is $\|A_i\|^2$ for $i\in[m]$, and depth of each tree is
at most $\lceil\log n\rceil$. Here, dequantization questions the assumption
of `\emph{qauntum access} to the data structure that can efficiently handle
classical inputs' and provides a fair comparison. Goal is to classically
construct identical tree with only a polynomial slowdown. 
\begin{defn}[\cite{tang2023} Definition 4.1]
  For all $i\in[n]$, if we can query for $v(i)$, we have \emph{query access}
  to a vector $v\in\mathbb{C}^n$, denoted by $Q(v)$. For all 
  $(i,j)\in[m]\times[n]$, if we can query for $A_{ij}$, we have $Q(A)$ to
  a matrix $A\in\mathbb{C}^{m\times n}$. Time cost of such query is denoted
  by $q(v)$ and $q(A)$, respectively.
\end{defn}
\begin{defn}[\cite{tang2023} Definition 4.2]
  For a vector $v\in\mathbb{C}^n$, we have \emph{sampling and query access} to
  $v$, denoted by $SQ(v)$, if we can:
  \begin{enumerate}
    \item have query access to $v$;
    \item obtain independent samples $i\in[n]$ following the distribution
      $\mathcal{D}_v\in\mathbb{R}^n$ with $\mathcal{D}_v(i):=|v(i)|^2/\|v\|^2$;
    \item have query access to $\|v\|$.
  \end{enumerate}
  Cost of entry querying, index sampling, norm querying, are denoted as
  $q(v),s(v),$ and $n(v)$, respectively. Also, let $sq(v):=\max(q(v),s(v),n(v))$.
\end{defn}
Samples obtained from sampling and query access are analogue to the quantum
state $\ket{v} := 1/\|v\|\sum v_i\ket{i}$ in the computational basis. Such
sampling and query access may be generalized by some oversampling rate.
\begin{defn}
  For $v\in\mathbb{C}^n$ and $\phi\geq1$, we have
  $\widetilde{v}\in\mathbb{C}^n$ if $\|\widetilde{v}\|^2=\phi\|v\|^2$ and
  $|\widetilde{v}_i|^2\geq |v_i|^2$ for all $i\in[n]$.
\end{defn}
\begin{defn}[\cite{tang2023} Definition 4.3]
  For $v\in\mathbb{C}^n$ and $\phi\geq1$, if $Q(v)$ and 
  $SQ(\widetilde{v})$ for $\widetilde{v}\in\mathbb{C}^n$, we have 
  $\phi$-\emph{oversampling and query access to $v$} or $SQ_{\phi}(v)$. Also,
  \begin{align*}
    s_{\phi}(v) := s(\widetilde{v}),\;
    q_{\phi}(v) := q(\widetilde{v}),\;
    n_{\phi}(v) := n(\widetilde{v}),\;
    sq_{\phi}(v) := \max(s_{\phi}(v),q_{\phi}(v),n_{\phi}(v)).
  \end{align*}
\end{defn}

\begin{figure}[h]
  \begin{forest}
    for tree={
      edge={-{Stealth[]}},
    }
      [$\|\widetilde{A}\|^2$
        [$\|\widetilde{A_1}\|^2$
        [$\|\widetilde{A_{11}}\|^2+\|\widetilde{A_{12}}\|^2$
          [$\|\widetilde{A_{11}}\|^2$
            ]
            [
            $\|\widetilde{A_{12}}\|^2$
            ]
          ]
          [$\|\widetilde{A_{13}}\|^2+\|\widetilde{A_{14}}\|^2$
          [$\|\widetilde{A_{13}}\|^2$
            ]
            [$\|\widetilde{A_{14}}\|^2$
            ]
          ]
        ]
        [$\|\widetilde{A_2}\|^2$
        [$\|\widetilde{A_{21}}\|^2+\|\widetilde{A_{22}}\|^2$
          [$\|\widetilde{A_{21}}\|^2$
            ]
            [$\|\widetilde{A_{22}}\|^2$
            ]
          ]
          [ $\|\widetilde{A_{23}}\|^2+\|\widetilde{A_{24}}\|^2$
          [$\|\widetilde{A_{23}}\|^2$
            ]
            [$\|\widetilde{A_{24}}\|^2$
            ]
          ]
        ]
      ]
  \end{forest}
  \caption{example of a $\phi$-sampling and qeury access data structure}
\end{figure}
Note that $SQ_{\phi}(v)$ constructs an identical tree structure to the one
from QRAM. So, we can dequantize whenever QML algorithm relies on QRAM
based data structure. 
\section{Alternative Data Structures}
However, there have been variations for such definitions of QRAM, which might
prevent dequantization. We first present such variant with general approach,
then with more concrete form of presentation by \emph{block-encoding}.
Theorem below constructs a more efficient variant of QRAM, where the memory
requirement \cite{kerenidis2020} is $\widetilde{\mathcal{O}}(mn)$ and time cost
of update, insertion, or deletion for a single entry is
$\mathcal{O}(\textrm{polylog}(n))$.
of art. 
\begin{thm}[\cite{kerenidis2020} Theorem IV.2]
  Let $M=\max_{i\in[m]}\|a_i\|^2$ and $A\in\mathbb{R}^{m\times n}$. There
  eixsts an efficient QRAM data structure for storing matrix entries
  $(i,j,a_{ij})$ such that access to this data structure allows a quantum
  algorithm to implement following unitary in time 
  $\widetilde{\mathcal{O}}(\log (mn))$.
  \[
    U\ket{i,0^{\lceil\log(n+1)\rceil}} = \ket{i}\frac{1}{\sqrt{M}}
    \left(\sum_{j\in[n]}a_{ij}\ket{j}+(M-\|a_i\|^2)^{1/2}\ket{n+1}\right).k
  \]
\end{thm}
Before heading to the proof, it is helpful to understand utility of $M$.
\begin{defn}
  The normalized vector state corresponding to vector $x\in\mathbb{R}^n$ and
  $M\in\mathbb{R}$ such that $\|x\|^2\leq M$ is the quantum state
  \[
    \ket{\bar{x}} = \frac{1}{\sqrt{M}}
    \left(\sum_{i\in[n]}x_i\ket{i}+(M-\|x\|^2)^{1/2}\ket{n+1}\right).
  \]
\end{defn}
So the key variation is the norm in the input state.
\begin{proof}
  $m$ binary trees $B_i$ $\longrightarrow$ use {\bfseries rotation}
  \begin{align*}
    \bullet\\\bullet \\\bullet
  \end{align*}
\end{proof}
Now we define the notion of block-encoding to clarify the prevention
of result above. Block-encdoing was devised during a optimal
solution of Hamiltonian simulation probem, \cite{low2019} originally termed
as `qubitization'. Simply put, block-encoding is a technique of representing
Hermitian or subnormalized matrix as the top-left block of a unitary matrix, 
that is;
\[
  U=\begin{bmatrix}A/\alpha &\cdot \\ \cdot &\cdot \end{bmatrix}
\]
where $\cdot$ denotes arbitrary elements of $U$. 
\begin{defn}[Gily\'en 2019] For $A\in\mathbb{C}^{n\times m}, \alpha,\epsilon
  \in\mathbb{R}_{+}$ and $a\in\mathbb{N}$, $(s+a)$-qubit unitary $U$ is an
  $(\alpha,a,\epsilon)$-block-encoding of $A$ if
  \[
    \|A-\alpha(\bra0^{\otimes a}\otimes I)U(\ket0^{\otimes a}\otimes I)\|\leq
    \epsilon.
  \]
\end{defn}
For $n,m\leq 2^s$ we may define an embedding matrix $A_e\in
\mathbb{C}^{2^s\times 2^s}$ such that the top-left block of $A_e$ is $A$ and
all other entries are $0$.

\begin{thm}[Chakraborty, 2019, Lemma 25]
  Let $A\in\mathbb{C}^{m\times n}$.
  \begin{enumerate}
    \item Fix $p\in [0,1]$. If $A^{(p)}$ and $(A^{(1-p)})^{\dagger}$ are both
      stored in quantum-accessible data structures, then there exist
      unitaries $U_R$ and $U_L$ that can be implemented in time
      $\mathcal{O}(\textrm{\normalfont polylog}(mn/\epsilon))$ such that
      $U_R^{\dagger}U_L$ is a $(\mu_p(A), \lceil\log(n+m+1)\rceil, 
      \epsilon)$-block-encoding of $\bar{A}$.
    \item On th other hand, if $A$ is stored in a quantum-accessible data
      structure, then there exist unitaries $U_R$ and $U_L$ that can
      be implemented in time $\mathcal{O}(\textrm{\normalfont polylog}(mn/\epsilon))$ such
      that $U_R^{\dagger}U_L$ is a $(\|A\|_F, \lceil\log(m+n)\rceil,
      \epsilon)$-block-encoding of $\bar{A}$.
  \end{enumerate}
\end{thm}

\begin{thm}
  Chakraborty2019 
\end{thm}

\begin{thm}
  main result 
\end{thm}

\section{Examples and Applications}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
%                                             %
%          Text for Introduction              %
%                                             %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
%                                             %
%          Text for main results              %
%                                             %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\bigskip
{\bf Conflicts of interest} : {Declare conflicts of interest or state ``The authors declare no conflict of interest.'' Authors must identify and declare any personal circumstances or interest that may be perceived as inappropriately influencing the representation or interpretation of reported research results.} 

%% Optional-------------------------------------------------------------
\bigskip
{\bf Data availability} : {In this section, please provide details regarding where data supporting reported results can be found, including links to publicly archived datasets analyzed or generated during the study. If the study did not report any data, you might add ``Not applicable'' here.} 
%-----------------------------------------------------------------------

%% Optional-------------------------------------------------------------
\bigskip
{\bf Acknowledgments} : {In this section you can acknowledge any support given which is not covered by the author contribution or funding sections.}
%-----------------------------------------------------------------------


\bigskip
%bib files are not available.-------------------------
\bibliographystyle{amsplain}
\begin{thebibliography}{0}

%ref-book----------------------------------------------
\bibitem{bc} 
C. Baiocchi and A. Capelo, 
{\it Variational and Quasi Variational Inequalities}, 
J. Wiley and Sons, 
New York, 
1984.

%ref-journal-------------------------------------------
\bibitem{harrow2009}
A. W. Harrow, A. Hassidim and S. Lloyd,
{\it Quantum algorithm for linear Systems of equations},
Phys. Rev. Lett
{\bf 103} (2009),
150502.

\bibitem{aaronson2015}
S. Aaronson,
{\it Read the fine print},
Nature Phys
{\bf 11} (2015),
291-293.

\bibitem{kerenidis2017}
I. Kerenidis and A. Prakash,
{\it Quantum Recommendation Systems},
ITCS
{\bf 67} (2017),
49:1--49:21.

\bibitem{babbush2018}
R. Babbush, C. Gidney, B. Dominic, N. Weibe, J. McClean, A. Paler, A. Fowler
and H. Neven,
{\it Encoding Electronic Spectra in Quantum Circuits with Linear $T$ Complexity}
Phys. Rv.
{\bf 8} (2018),
041015.

\bibitem{low2019}
H. Low and I. Chuang,
{\it Hamiltonian Simulation by Qubitization},
Quantum
{\bf 3} (2019),
163.

\bibitem{chakraborty2019}
Chakraborty, Gily{\'en} and Jeffery. {\it The Power of Block-Encoded Matrix
Powers}, ICALP {\bf 132} (2019), 33:1-33:14.

\bibitem{tang2019}
E. Tang. {\it A Quantum-Inspired Classical Algorithm for Recommendation Systems},
Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing (2019),
217--228.

\bibitem{kerenidis2020}
Kerenidis, Iordanis and Prakash, Anupam, 
{\it Quantum gradient descent for linear systems and leaste squares}, 
Phys.Rev.A {\bf 2} (2020), 
022316.

\bibitem{jaques2023}
S. Jaques and A. Rattew,
{\it QRAM: A Survey and Critique},
arXiv: 2305.10310 [quant-ph] (2023).

\bibitem{tang2023}
E. Tang,
{\it Quantum Machine Learning Without Any Quantum},
Ph.D. diss, University of Washington (2023).

\bibitem{cp} 
D. Chan and J.S. Pang, 
{\it The generalized quasi variational inequality problems}, 
Math. Oper. Research 
{\bf 7} (1982), 
211-222.

\bibitem{belly} 
C. Belly, 
{\it Variational and Quasi Variational Inequalities}, 
J. Appl. Math. and Computing 
{\bf 6} (1999), 
234-266.

\bibitem{pang} 
D. Pang, 
{\it The generalized quasi variational inequality problems}, 
J. Appl. Math. and Computing 
{\bf 8} (2002), 
123-245.



\bigskip
\bigskip

%Type a brief sketch of biography and research interests not exceeding 85 words.------------------------
%The following is a sample biography

\pn {\bf 1st Author name} received M.Sc. from Seoul National University and Ph.D. at University of Minnesota. 
Since 1992 he has been at Chungnam National University. 
His research interests include numerical optimization and biological computation.

\medskip
\pn % Affiliations / Addresses
Department of Mathematics, Chungnam National University, Daejeon 305-764, Korea. 
\pn{\tt e-mail: soh@cnu.ac.kr}

\bigskip
\pn {\bf 2nd Author name} received M.Sc. from Kyungpook National University, and Ph.D. from Iowa State University. 
He is currently a professor at Chungbuk National University since 1991. 
His research interests are computational mathematics, iterative method and parallel computation.

\medskip
\pn % Affiliations / Addresses
Department of Mathematics, College of Natural Sciences, Chungbuk National University, Cheongju 361-763, Korea.
\pn{\tt e-mail: gmjae@chungbuk.ac.kr}



\end{thebibliography}

\end{document}
