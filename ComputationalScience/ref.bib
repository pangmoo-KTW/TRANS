@ARTICLE{Feynman1982,
  AUTHOR = {Feynman, Richard P.},
  DATE = {1982-06-01},
  DOI = {10.1007/BF02650179},
  ISSN = {1572-9575},
  JOURNALTITLE = {International Journal of Theoretical Physics},
  NUMBER = {6},
  PAGES = {467--488},
  TITLE = {Simulating Physics with Computers},
  VOLUME = {21},
}
@article{Frieze2004,
author = {Frieze, Alan and Kannan, Ravi and Vempala, Santosh},
title = {Fast Monte-Carlo Algorithms for Finding Low-Rank Approximations},
year = {2004},
issue_date = {November 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0004-5411},
url = {https://doi.org/10.1145/1039488.1039494},
doi = {10.1145/1039488.1039494},
abstract = {We consider the problem of approximating a given m \texttimes{} n matrix A by another matrix of specified rank k, which is smaller than m and n. The Singular Value Decomposition (SVD) can be used to find the "best" such approximation. However, it takes time polynomial in m, n which is prohibitive for some modern applications. In this article, we develop an algorithm that is qualitatively faster, provided we may sample the entries of the matrix in accordance with a natural probability distribution. In many applications, such sampling can be done efficiently. Our main result is a randomized algorithm to find the description of a matrix D* of rank at most k so that holds with probability at least 1 − δ (where |·|F is the Frobenius norm). The algorithm takes time polynomial in k,1/ϵ, log(1/δ) only and is independent of m and n. In particular, this implies that in constant time, it can be determined if a given matrix of arbitrary size has a good low-rank approximation.},
journal = {J. ACM},
month = {nov},
pages = {1025–1041},
numpages = {17},
keywords = {Matrix algorithms, sampling, low-rank approximation}
}
@article{HHL2009,
  title = {Quantum Algorithm for Linear Systems of Equations},
  author = {Harrow, Aram W. and Hassidim, Avinatan and Lloyd, Seth},
  journal = {Phys. Rev. Lett.},
  volume = {103},
  issue = {15},
  pages = {150502},
  numpages = {4},
  year = {2009},
  month = {Oct},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.103.150502},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.103.150502}
}
@article{Aaronson2015,
  title={Read the fine print},
  author={Scott Aaronson},
  journal={Nature Physics},
  year={2015},
  volume={11},
  pages={291 - 293},
  url={https://api.semanticscholar.org/CorpusID:122167250}
}
@InProceedings{KP2017,
  author =	{Iordanis Kerenidis and Anupam Prakash},
  title =	{{Quantum Recommendation Systems}},
  booktitle =	{8th Innovations in Theoretical Computer Science Conference (ITCS 2017)},
  pages =	{49:1--49:21},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-029-3},
  ISSN =	{1868-8969},
  year =	{2017},
  volume =	{67},
  editor =	{Christos H. Papadimitriou},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{http://drops.dagstuhl.de/opus/volltexte/2017/8154},
  URN =		{urn:nbn:de:0030-drops-81541},
  doi =		{10.4230/LIPIcs.ITCS.2017.49},
  annote =	{Keywords: Recommendation systems, quantum machine learning, singular value estimation, matrix sampling, quantum algorithms.}
}
@inproceedings{Tang2019,
author = {Tang, Ewin},
title = {A Quantum-Inspired Classical Algorithm for Recommendation Systems},
year = {2019},
isbn = {9781450367059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313276.3316310},
doi = {10.1145/3313276.3316310},
booktitle = {Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing},
pages = {217–228},
numpages = {12},
keywords = {sampling, low-rank approximation, recommender systems, exponential speedup, quantum machine learning},
location = {Phoenix, AZ, USA},
series = {STOC 2019}
}
@article{Cotler2021,
  title={Revisiting dequantization and quantum advantage in learning tasks},
  author={Jordan S. Cotler and Hsin-Yuan Huang and Jarrod R. McClean},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.00811},
  url={https://api.semanticscholar.org/CorpusID:244799603}
}
@article{Huang2022,
author = {Hsin-Yuan Huang  and Michael Broughton  and Jordan Cotler  and Sitan Chen  and Jerry Li  and Masoud Mohseni  and Hartmut Neven  and Ryan Babbush  and Richard Kueng  and John Preskill  and Jarrod R. McClean },
title = {Quantum advantage in learning from experiments},
journal = {Science},
volume = {376},
number = {6598},
pages = {1182-1186},
year = {2022},
doi = {10.1126/science.abn7293},
URL = {https://www.science.org/doi/abs/10.1126/science.abn7293},
eprint = {https://www.science.org/doi/pdf/10.1126/science.abn7293}
}
@misc{Bakshi2023,
title={An Improved Classical Singular Value Transformation for Quantum Machine Learning}, 
author={Ainesh Bakshi and Ewin Tang},
year={2023},
eprint={2303.01492},
archivePrefix={arXiv},
primaryClass={quant-ph}
}
@article{Childs2017,
author = {Childs, Andrew M. and Kothari, Robin and Somma, Rolando D.},
title = {Quantum Algorithm for Systems of Linear Equations with Exponentially Improved Dependence on Precision},
year = {2017},
issue_date = {January 2017},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {46},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/16M1087072},
doi = {10.1137/16M1087072},
abstract = {Harrow, Hassidim, and Lloyd [Phys. Rev. Lett., 103 (2009), 150502] showed that for a suitably specified $N times N$ matrix $A$ and an $N$-dimensional vector $vec{b}$, there is a quantum algorithm that outputs a quantum state proportional to the solution of the linear system of equations $Avec{x} = vec{b}$. If $A$ is sparse and well-conditioned, their algorithm runs in time ${poly}(log N, 1/epsilon)$, where $epsilon$ is the desired precision in the output state. We improve this to an algorithm whose running time is polynomial in $log(1/epsilon)$, exponentially improving the dependence on precision while keeping essentially the same dependence on other parameters. Our algorithm is based on a general technique for implementing any operator with a suitable Fourier or Chebyshev series representation. This allows us to bypass the quantum phase estimation algorithm, whose dependence on $epsilon$ is prohibitive.},
journal = {SIAM J. Comput.},
month = {jan},
pages = {1920–1950},
numpages = {31},
keywords = {linear systems, quantum complexity, 68Q12, quantum algorithms, 65F05}
}
@inproceedings{Gilyen2019,
author = {Gilyén, András and Su, Yuan and Low, Guang Hao and Wiebe, Nathan},
year = {2019},
month = {06},
pages = {193-204},
title = {Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics},
doi = {10.1145/3313276.3316366}
}
@article{Rall2020,
  title = {Quantum algorithms for estimating physical quantities using block encodings},
  author = {Rall, Patrick},
  journal = {Phys. Rev. A},
  volume = {102},
  issue = {2},
  pages = {022408},
  numpages = {9},
  year = {2020},
  month = {Aug},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.102.022408},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.102.022408}
}

